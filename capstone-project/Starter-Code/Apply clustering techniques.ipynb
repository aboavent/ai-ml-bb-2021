{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML : Clustering stock market data\n",
    "\n",
    "**Goal**: Learn about approximate nearest neighbor identification in high-dimensional spaces via:\n",
    "\n",
    "1. Clustering times series based on its shape using [K-Shape: Time Series Clustering](https://aws.amazon.com/marketplace/pp/Spotad-LTD-K-Shape-Time-Series-Clustering/prodview-bjbovimwn5ajs). \n",
    "2. Clustering high-dimensional data using Amazon SageMaker built-in [K-Means Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html)\n",
    "\n",
    "#### Task 1 description:\n",
    "In this task, you will learn how to perform clustering on time series data and identify stocks that are performing identical to each other over a given time-span. You will download the stock market data at runtime, normalize values for each stock, and then identify clusters of stocks with identical shape. You will then share findings about which stocks seem to have identical behaviors. You will also report which value for `k` returned you the minimum SSD (Sum of the squared distances between each data point and the cluster centroid). \n",
    "\n",
    "To help you ensure you have sufficient time for experimentation in Task 2, some starter code for task 1 has been provided in this notebook. \n",
    "\n",
    "\n",
    "#### *References:*\n",
    "\n",
    "* https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/\n",
    "* Accelerating ML projects with algorithms and models from AWS Marketplace (https://youtu.be/OrmHHVI1uPk?t=1682)\n",
    "* Interesting graphs -https://github.com/awslabs/amazon-sagemaker-examples/blob/master/aws_marketplace/using_model_packages/financial_transaction_processing/Extracting_insights_from_your_credit_card_statement.ipynb\n",
    "\n",
    "#### Task 2 description:\n",
    "In this task, you will learn how to identify approximate nearest neighbors in high-dimensional space by applying a clustering algorithm. As part of this task, you will first generate high-dimensional synthetic datasets containing trading portfolio tickers. You will then apply K-Means clustering algorithm and clusters of traders that have identical portfolios. \n",
    "\n",
    "**Notes**:\n",
    "\n",
    "* To make this a fun project, add tickers you have special interest in, to the list.\n",
    "* Extra time left? \n",
    "    Explore other algorithms you can use to solve problems identified in Task 1 and 2 and compare the results using appropriate metrics.\n",
    "\n",
    "\n",
    "#### *References:*\n",
    "\n",
    "* https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/\n",
    "* [How K-Means algorithm works](https://docs.aws.amazon.com/sagemaker/latest/dg/algo-kmeans-tech-notes.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this experiment, you may use following tickers.\n",
    "tickers = ['FB','AAPL','MSFT','GOOGL','GOOG','JNJ','V','PG','JPM','UNH','HD','MA','INTC','NVDA','VZ','NFLX','ADBE','DIS','T','PYPL','PFE','MRK','CSCO','CMCSA','WMT','PEP','BAC','XOM','KO','CRM','ABBV','ABT','CVX','TMO','AMGN','COST','MCD','ACN','LLY','BMY','NEE','MDT','AVGO','LIN','TXN','DHR','UNP','NKE','AMT','ORCL','PM','IBM','LOW','HON','QCOM','C','GILD','BA','WFC','RTX','LMT','MMM','BLK','SBUX','FIS','SPGI','NOW','CHTR','CVS','UPS','VRTX','BDX','INTU','ISRG','MDLZ','MO','CAT','CCI','BKNG','PLD','ZTS','AMD','REGN','GS','ANTM','D','CI','EQIX','APD','ADP','CL','ATVI','MS','AXP','TJX','SYK','CB','TMUS','TGT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import sagemaker as sage\n",
    "import yfinance as yf\n",
    "import botocore\n",
    "from sklearn import preprocessing\n",
    "from uuid import uuid4\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from scipy.stats import zscore\n",
    "from sagemaker import AlgorithmEstimator\n",
    "from matplotlib.pyplot import figure\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "#visualization variables\n",
    "palette=sns.color_palette(\"RdBu\", n_colors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common variable declaration\n",
    "region_name = boto3.Session().region_name\n",
    "bucket=sage.Session().default_bucket()\n",
    "role = sage.get_execution_role()\n",
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dont worry about the following warning. Note that cell has executed successfully.\n",
    "\n",
    "`Couldn't call 'get_role' to get Role ARN from role name Sagemaker_Studio_Role to get Role path.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "In this project, you will find stocks that have identical shape. This task has been divided into following three steps:\n",
    "\n",
    "##### Step 1:\n",
    "* Download stock market data for 95 days and write data to a file in a format accepted by the algorithm. Algorithm requires you to prepare a CSV file containing normalized time series data where each row contains a time-series for a stock.\n",
    "\n",
    "##### Step 2:\n",
    "* Perform shape based time series clustering and identify clusters of stocks that are performing identically - Remember, magnitude does not matter but shape does!\n",
    "\n",
    "##### Step 3:\n",
    "Experiment and report findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, you will use [K-Shape Time Series Clustering algorithm](https://aws.amazon.com/marketplace/pp/Spotad-LTD-K-Shape-Time-Series-Clustering/prodview-bjbovimwn5ajs)  from [AWS Marketplace](https://aws.amazon.com/marketplace/search/results?page=1&filters=fulfillment_options&fulfillment_options=SAGEMAKER&ref_=header_nav_dm_sagemaker). The K-Shape Time Series Clustering algorithm is based on [this research paper](\n",
    "http://web2.cs.columbia.edu/~gravano/Papers/2015/sigmod2015.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure dates for which you would like to download the data\n",
    "start_date = '2020-02-03'\n",
    "end_date = '2020-06-18'\n",
    "common_prefix = \"k-shape-clustering\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets download the stock data for all specified tickers.\n",
    "data = yf.download(' '.join(tickers), start=start_date, end=end_date, group_by=\"ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all dates for which stock prices are available into a column.\n",
    "dates=data[tickers[0]]['Close'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dates)\n",
    "##df[dates].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experimentation, we will only use closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_data=[]\n",
    "\n",
    "for ticker in tickers:\n",
    "    ticker_data=[ticker]\n",
    "    ticker_data.extend(data[ticker]['Close'].values)\n",
    "    close_data.append(ticker_data)\n",
    "\n",
    "#print('Closing price data set for ',len(close_data),' tickers')\n",
    "#print(close_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that `close_data` contains ticker and stock price time-series. Let us insert this data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Ticker']\n",
    "columns.extend(dates)\n",
    "\n",
    "df=pd.DataFrame(data=close_data,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data looks great! Now, we will normalize the data by row and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[dates].values\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To normalize the data by row instead of column, we will transpose it first, transform by applying MinMaxScaler, \n",
    "# and then will transpose it back to coonvert it back to columnar format.\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit(x.T)\n",
    "x_scaled=minmax_scale.transform(x.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='train.csv'\n",
    "\n",
    "#Lets write scaled column values to a dataframe, insert `Ticker` column, and the save it to a file to later feed it to an algorithm as part of the training job.\n",
    "df = pd.DataFrame(x_scaled)\n",
    "df.insert(0,'Ticker',tickers)\n",
    "df.to_csv(file_name,header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we will upload it to Amazon S3 so that we can specify the same as part of the training job in Step 2.\n",
    "train_file = sagemaker_session.upload_data(file_name, bucket, common_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Train an ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third party algorithms from AWS Marketplace work with Amazon SageMaker and require a subscription. To subscribe:\n",
    "\n",
    "1. Open the algorithm [AWS Marketplace listing page](https://aws.amazon.com/marketplace/pp/Spotad-LTD-K-Shape-Time-Series-Clustering/prodview-bjbovimwn5ajs)\n",
    "1. Click on **Continue to subscribe** button.\n",
    "1. If you are trying this notebook as part of a workshop conducted by AWS, a subscription has been created for you and **Continue to configuration** button is active. However, If your trying this notebook in your own AWS account, On the ***Subscribe to this software*** page, **\"Accept Offer\"** button needs to be clicked if you agree with EULA, pricing, and support terms.\n",
    "1. Click on **Continue to configuration** button and then choose a **region** corresponding to the AWS Region in which you launched notebook,\n",
    "1. you will see a **Product Arn**. Copy the ARN and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn='<Customer to specify algorithm ARN corresponding to their AWS region after subscription>'\n",
    "\n",
    "#algo_arn='arn:aws:sagemaker:us-east-1:865070037744:algorithm/k-shape-cd639040558775d27d890f1479c92d7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review hyperparameters (k=11 for 11 clusters, label-size=1 since we have first column in the data as the ticker)\n",
    "#Review instance-type, and train an ML model.\n",
    "\n",
    "algo = AlgorithmEstimator(algorithm_arn=algo_arn, \n",
    "                          role=role, \n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.m5.4xlarge', \n",
    "                          sagemaker_session=sagemaker_session, \n",
    "                          base_job_name=common_prefix,\n",
    "                          hyperparameters={\"k\": \"11\", \"label_size\": \"1\"}) \n",
    "\n",
    "algo.fit({'train': train_file}) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm allows us to download and inspect the ML model generated which contains information about centroids.  Cluster centroids are means of the variables in the cluster. In this case, it is the cluster center time series for  the time series observations found in the cluster.\n",
    "\n",
    "To find a cluster to which a point belongs, the algorithm finds the distance of that time-sries from all of the cluster centers. It then chooses the cluster with the closest center as the cluster to which the observation belongs.\n",
    "\n",
    "Lets download the model and plot cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "try:\n",
    "    s3.Bucket(bucket).download_file('{}/output/model.tar.gz'.format(algo._current_job_name), 'model.tar.gz')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    if e.response['Error']['Code'] == \"404\":\n",
    "        print(\"The object does not exist.\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model\n",
    "!tar -zxvf model.tar.gz -C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_comma = lambda s: str.split(s, ',')\n",
    "\n",
    "centroids = list()\n",
    "with open('model/centroids', 'r') as f:\n",
    "    for index,record in enumerate(map(split_by_comma, list(map(str.strip, f)))):\n",
    "        centroid=np.array(record).astype(float)\n",
    "        centroids.append(centroid)\n",
    "len(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot centroid lines for clusters identified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that centroids are Z-normalized and their range does not match with original stock range. Add code in following cell to create a line chart containing  centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(num=None, figsize=(14, 6), dpi=150, facecolor='w', edgecolor='k')\n",
    "\n",
    "#Display only month and day\n",
    "formatter = mdates.DateFormatter(\"%m-%d\")\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "\n",
    "for index,centroid in enumerate(centroids):\n",
    "    plt.plot( dates, centroid, linewidth=1, label='Centroid '+str(index))\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, deploy the ML model and peform an inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictor = algo.deploy(1, 'ml.m5.4xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_result=df.head(1).values[0]\n",
    "result=predictor.predict(np.array(single_result[1:])).decode('utf-8')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Task for workshop attendees: Perform inference on entire training dataset and identify cluster-id for each row. Plot each cluster separately in form of a line chart.  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Report your findings in the next cell. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully performed K-shape based time series clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment Summary\n",
    "\n",
    "<font color='red'>Task: Next, we recommend that each member in the group to replicate the working notebook and perform one or more experiments for different values of K from k=2 to k=20, (Step 2: Train an ML model onwards) and report `Sum Square Distance` in following section.\n",
    "    \n",
    "For this experiment, do not use Automatic model tuning. The goal of this exercise is to ensure that every team member understands the experimentation process for the problem at hand so that your team can solve task 2 more efficiently.\n",
    "\n",
    "For experimentation, you may choose another set of tickers/date-range. But rememeber, you must provide:\n",
    "1. At-least 50 tickers\n",
    "2. Atleast 3 month date range.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample Experiment summary:\n",
    "<font color='red'>Tickers =[]\n",
    "\n",
    "Date range=[]\n",
    "\n",
    "\n",
    "| K      | Sum Square Distance |\n",
    "| ----------- | ----------- |\n",
    "| Header      | Title       |\n",
    "| Paragraph   | Text        |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Can you answer following questions:\n",
    "* What value of \"K\" gave you the best results?\n",
    "* Do all tickers in the same sector have identical shape?\n",
    "* Note an interesting trend you discovered from graphs\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once each member has finished the task, work on Task 2 together as a team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2 Description \n",
    "Despite stock markets being volatile, a large number of people have invested in stocks.  Each of us likes to think that we have a unique stock portfolio. While quantity and purchase date may vary, it is highly unlikely that the collection of tickers in your portfolio is unique. \n",
    "\n",
    "You first task is simple, you need to generate synthetic portfolios for 100,000 traders with each trader having stocks of at-least 3 companies and at-most 10 companies. \n",
    "\n",
    "##### Step 1:\n",
    "For given tickers collection(a subset from SPDR SP 500 ETF: (SPY)), create ticker portfolios for 20,000 traders. Give a unique id to each trader. \n",
    "\n",
    "##### Step 2:\n",
    "Perform K-Means clustering on the portfolio tickers by running KMeans clustering algorithm, see [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html).\n",
    "        \n",
    "        K-means is an unsupervised learning algorithm. It attempts to find discrete groupings within data, where members of a group are as similar as possible to one another and as different as possible from members of other groups. You define the attributes that you want the algorithm to use to determine similarity.\n",
    "    Amazon SageMaker has a modified version of the web-scale k-means clustering algorithm. Compared with the original version of the algorithm, the version used by Amazon SageMaker is more accurate. Like the original algorithm, it scales to massive datasets and delivers improvements in training time.For more information about KMeans clustering algorithm, see [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/k-means.html)\n",
    "\n",
    "\n",
    "**Goal**: Develop a function that accepts a trader-id at run-time and identify other traders that have a portfolio identical (at least 90% match - quantity does not matter) to the chosen trader.\n",
    "\n",
    "##### Step 3:\n",
    "Perform experiementation with different values for \"K\" and summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro Tip**: To avoid delays, start development with a small dataset and then run your experiment on large data configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate portfolios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Proposed pandas dataframe columns`: ['TRADER_ID','Ticker1','Ticker2','Ticker3','Ticker4'...'TickerN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traders=20000\n",
    "min_stocks_in_portfolio=3\n",
    "max_stocks_in_portfolio=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "#Each trader's portfolio must contain 3 companies and at-most 10 companies.\n",
    "portfolios=[]\n",
    "for trader_number in range(num_traders):\n",
    "    total_stocks= randrange(min_stocks_in_portfolio, max_stocks_in_portfolio)\n",
    "    for num_stock in range(total_stocks):\n",
    "        df.loc[trader_number, tickers[randrange(len(tickers))]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro Tip**: If its taking a lot of time for you to run this then check if you can run this code on higher infrastructure configuration, choose a larger instance type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:\n",
    "<font color='red'>\n",
    "In this section, you need to write code required to train an ML model for clustering different data points in the portfolios generated.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "<font color='red'>\n",
    "In this section, write code required to select a trader and then find others who have tickers in their portfolios identical to the chosen trader's portfolio </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Identify optimal value for K and report metrics (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the blog-post:\n",
    "https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/ \n",
    "    \n",
    "Perform an experimentation identical to the blog-post, plot an elbow graph, and share your results."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
